---
title: "Chapter 7 Problem Set Solutions"
output:
  html_document:
    df_print: paged
---

```{r packages}
library(ggplot2)
library(readxl)
setwd("C:/Users/timma/Documents/GitHub/FIN6572Fall2020/Problem Sets/Ch7")
```

### 7.1

```{r 7.1data}
myData = read_xlsx("Ch7_Q4_Data_File.xlsx")
```

Model 1 (No Interaction):
```{r 7.1a}
Model1 <- lm(y ~ x + d1 + d2, data = myData)
summary(Model1)
```

Model 2 (Interaction):
```{r 7.1b}
Model2 <- lm(y ~ x + d1 + d2 + d1*d2, data = myData)
summary(Model2)
```

Calculate predicted values from Model 1.
```{r 7.1c}
x = 20
d1 = 1
d2 = 0
Model1$coefficients[1] + Model1$coefficients[2]*x + Model1$coefficients[3]*d1 + Model1$coefficients[4]*d2
d2 = 1
Model1$coefficients[1] + Model1$coefficients[2]*x + Model1$coefficients[3]*d1 + Model1$coefficients[4]*d2
```


### 7.2

```{r 7.2data}
myData = read_xlsx("Ch7_Q9_Data_File.xlsx")
```

a.1 Multiple Linear Regression Model:
```{r 7.2a1}
Model1 <- lm(Income~ Hours + Hot + Holiday, data = myData)
summary(Model1)
```

a.2 Predict scenarios:
```{r 7.2a2}
hours = 6
hot = 1
holiday = 1
Model1$coefficients[1] + Model1$coefficients[2]*hours + Model1$coefficients[3]*hot + Model1$coefficients[4]*holiday
holiday = 0
Model1$coefficients[1] + Model1$coefficients[2]*hours + Model1$coefficients[3]*hot + Model1$coefficients[4]*holiday
```

b.1 Multiple Linear Regression Model (with Interaction):
```{r 7.2b1}
Model2 <- lm(Income ~ Hours + Hot + Holiday + Hot*Holiday, data = myData)
summary(Model2)
```

b.2 Predict scenarios:
```{r 7.2b2}
hours = 6
hot = 1
holiday = 1
Model2$coefficients[1] + Model2$coefficients[2]*hours + Model2$coefficients[3]*hot + Model2$coefficients[4]*holiday + Model2$coefficients[5]*hot*holiday
holiday = 0
Model2$coefficients[1] + Model2$coefficients[2]*hours + Model2$coefficients[3]*hot + Model2$coefficients[4]*holiday + Model2$coefficients[5]*hot*holiday
```


### 7.3

```{r 7.3data}
myData = read_xlsx("Ch7_Q11_Data_File.xlsx")
```

a. Model 1: Linear Regression of Consumption on Income
```{r 7.3a}
Model1 <- lm(Consumption ~ Income, data = myData)
summary(Model1)
income = 75000
Model1$coefficients[1] + Model1$coefficients[2]*income
ggplot(myData,aes(y=Consumption,x=Income))+geom_point()+geom_smooth(method="lm")
```

b. Model 2: Include urban dummy (allow for each type of community to have a distinct intercept, but same slope)
```{r 7.3b1}
Model2 <- lm(Consumption ~ Income + Urban, data = myData)
summary(Model2)
equation1=function(x){coef(Model2)[1]+coef(Model2)[2]*x}
equation2=function(x){coef(Model2)[1]+coef(Model2)[2]*x+coef(Model2)[3]}
ggplot(myData,aes(y=Consumption,x=Income,color=Urban))+geom_point()+
        stat_function(fun=equation1,geom="line",color=scales::hue_pal()(2)[1])+
        stat_function(fun=equation2,geom="line",color=scales::hue_pal()(2)[2])
```

Predict consumption for family with $75k income in urban vs. rural communities.
```{r 7.3b2}
urban = 1
Model2$coefficients[1] + Model2$coefficients[2]*income + Model2$coefficients[3]*urban
urban = 0
Model2$coefficients[1] + Model2$coefficients[2]*income + Model2$coefficients[3]*urban
```

c. Model 3: Include interaction between urban dummy and income (allow for distinct intercepts and distinct slopes across the two community types)
```{r 7.3c1}
Model3 <- lm(Consumption ~ Income + Urban + Income*Urban, data = myData)
summary(Model3)
```

Predict consumption for family with $75k income in urban vs. rural communities using Model 3.
```{r 7.3c2}
urban = 1
Model3$coefficients[1] + Model3$coefficients[2]*income + Model3$coefficients[3]*urban + Model3$coefficients[4]*income*urban
urban = 0
Model3$coefficients[1] + Model3$coefficients[2]*income + Model3$coefficients[3]*urban + Model3$coefficients[4]*income*urban
```


### 7.4

a. Plot the quadratic relation: $\hat{y} = 20 + 1.9x - 0.05x^2$. Plug in $x=10,20,30$ for predicted values.
```{r 7.4}
x = 0:40
y = 20 + 1.9*x - 0.05*x^2
plot(x,y,'l')
```

b. The predicted response $\hat{y}$ is maximized when first derivative is equal to 0:

$\dfrac{dy}{dx} = 1.9 - 2*0.05x = 0 \implies x = \dfrac{1.9}{0.1} = 19$


### 7.5

Use each of the model designs to calculate the predicted repsonses.


### 7.6

```{r 7.6data}
myData = read_xlsx("Ch7_Q33_Data_File.xlsx")
```

Model 1: Linear Model ($y=X\beta+\epsilon$)
```{r 7.6a1}
Model1 <- lm(Rent ~ Beds+Baths+Sqft, data = myData)
summary(Model1)
ggplot(myData,aes(y=Rent,x=Sqft))+geom_point()+geom_smooth(method="lm")
```

Model 2: Exponential Model ($\ln(y) = X\beta+\epsilon$)
```{r 7.6a2}
Model2 <- lm(log(Rent) ~ Beds+Baths+Sqft, data = myData)
summary(Model2)
```

b. Predict rent for a \$1,500 sq.ft. house with 3 bed and 2 bath. For the exponential model, we must first calculate the bias correction term ($\sigma^2/2$) and add that before applying the exponential function.
```{r 7.6b}
bed = 3
bath = 2
size = 1500
Model1$coefficients[1] + Model1$coefficients[2]*bed + Model1$coefficients[3]*bath + Model1$coefficients[4]*size
SE<-summary(Model2)$sigma
exp(Model2$coefficients[1] + Model2$coefficients[2]*bed + Model2$coefficients[3]*bath + Model2$coefficients[4]*size + (SE^2/2))
```


c. Calculate $R^2$ for Model 2 by calculating fitted values for y and computing the correlation between  the predicted and actual y values.
```{r}
Pred_lny<-predict(Model2)
Pred_y<-exp(Pred_lny+SE^2/2)
cor(myData$Rent, Pred_y)^2
```


### 7.7

```{r 7.7data}
myData = read_xlsx("Ch7_Q35_Data_File.xlsx")
names(myData)[1] = "TimePerUnit"
names(myData)[2] = "UnitNumber"
```

Model 1: Linear Regression ($y=X*\beta+\epsilon$)
```{r 7.7a}
Model1 <- lm(TimePerUnit ~ UnitNumber, data = myData)
summary(Model1)
```

Model 2: Logarithmic Regression ($y=\ln(X)*\beta+\epsilon$)
```{r 7.7b}
Model2 <- lm(TimePerUnit ~ log(UnitNumber), data = myData)
summary(Model2)
```

Plug in unit 50 to the logarithmic model:
```{r 7.7c}
u = 50
t = Model2$coefficients[1] + Model2$coefficients[2]*log(u)
t
```


### 7.8

```{r 7.8data}
myData = read_xlsx("Ch7_Q37_Data_File.xlsx")
```


```{r 7.8a}
Model1 <- lm(log(Q) ~ log(L)+log(K), data = myData)
summary(Model1)
```


### 7.9

```{r 7.9data}
myData = read_xlsx("Ch7_Q43_Data_File.xlsx")
```

```{r 7.9a1}
Linear_Model <-lm(y ~ x1+x2, data =myData)
summary(Linear_Model)
```

```{r 7.9a2}
x1 = 12
x2 = 8
Linear_Model$coefficients[1]+Linear_Model$coefficients[2]*x1+Linear_Model$coefficients[3]*x2
```


Logistic regression model (aka logit) is designed to fit binary choice variables (dichotomous).
```{r 7.9b1}
Logistic_Model <- glm(y ~ x1 + x2, family = binomial(link = logit), data = myData)
summary(Logistic_Model)

newdat <- data.frame(x1=seq(min(myData$x1), max(myData$x1),len=100))
newdat$x2 = mean(myData$x2)
newdat$y = predict(Logistic_Model, newdata=newdat, type="response")
plot(y~x1, data=myData, col="red4")
lines(y ~ x1, newdat, col="green4", lwd=2)
```

Logistic fitted values:

$\hat{y} = \dfrac{e^{\beta_0+\beta_1x_1+\beta_2x_2}}{1+e^{\beta_0+\beta_1x_1+\beta_2x_2}}$
```{r 7.9b2}
x1 = 12
x2 = 8
(exp(Logistic_Model$coefficients[1]+Logistic_Model$coefficients[2]*x1+Logistic_Model$coefficients[3]*x2))/(1+exp(Logistic_Model$coefficients[1]+Logistic_Model$coefficients[2]*x1+Logistic_Model$coefficients[3]*x2))
```


### 7.10

```{r 7.10data}
myData = read_xlsx("Ch7_Q56_Data_File.xlsx")
```

First, partition the dataset into training (first 30 obs) and testing sets (last 10 obs). Then fit model to training set.
```{r 7.10a1}
TData <- myData[1:30,]
VData <- myData[31:40,]
Model1 <- lm(y ~ x + d, data = TData)
summary(Model1)
Model2 <- lm(y ~ x + d + x*d, data = TData)
summary(Model2)
```


```{r 7.10a2}
Pred1 <- predict(Model1, VData)
RMSE1 = sqrt(mean((VData$y-Pred1)^2))
Pred2 <- predict(Model2, VData)
RMSE2 = sqrt(mean((VData$y-Pred2)^2))
RMSE1
RMSE2
```


















